# Dataset and Baseline Implementation Summary

**Date**: October 31, 2024
**Project**: TacticAI-Style Corner Kick Prediction
**Status**: Phase 1 Complete, Ready for Baseline Training

---

## Executive Summary

âœ… **Dataset Ready**: 7,369 temporally augmented graphs with receiver labels (60% coverage)
âœ… **Baselines Implemented**: Random and MLP baselines coded and tested
âš ï¸ **Missing**: XGBoost baseline (not in current plan or code)
ğŸ”„ **Next Step**: Train baselines and validate data pipeline before proceeding to GNN training

---

## Our Dataset: Complete Description

### 1. Dataset Size and Coverage

```
Total Graphs:     7,369
â”œâ”€â”€ StatsBomb:    5,814 temporally augmented graphs
â”‚   â”œâ”€â”€ With receiver labels:  3,492 (60.1%)
â”‚   â”œâ”€â”€ Without receiver:      2,322 (39.9%)
â”‚   â””â”€â”€ Temporal augmentation: 5Ã— original + mirrors
â””â”€â”€ SkillCorner:  1,555 temporal graphs (from 317 base corners)
    â””â”€â”€ Real 10fps tracking data

Base Corners:     1,435 unique corner kick scenarios
Receiver Coverage: 60.1% of graphs have valid receiver labels
Dangerous Rate:   18.2% (shot OR goal outcomes)
```

**Important**: The receiver data loader filters to only graphs with receiver labels, giving us **~3,492 usable graphs** for TacticAI replication.

---

### 2. Graph Structure

**Nodes (Players)**:
- Average: ~19 players per graph
- Range: Varies (typically 18-22 players visible in freeze frame)
- Two teams: Attacking (team_flag=1.0) and Defending (team_flag=0.0)

**Edges**:
- Strategy: `adjacency_team` (teammates connected)
- Average: ~166 edges per graph
- Edge features: 6-dimensional (distance, relative velocity, angle)

**Node Features**: 14-dimensional per player

| Index | Feature Name          | Type        | Source      | Description                          |
|-------|-----------------------|-------------|-------------|--------------------------------------|
| 0     | `x`                   | Spatial     | StatsBomb   | X-coordinate (0-120 yards)          |
| 1     | `y`                   | Spatial     | StatsBomb   | Y-coordinate (0-80 yards)           |
| 2     | `dist_to_goal`        | Spatial     | Engineered  | Euclidean distance to goal center   |
| 3     | `dist_to_ball`        | Spatial     | Engineered  | Distance to ball landing zone       |
| 4     | `vx`                  | Kinematic   | Augmented   | Velocity X (synthetic/SkillCorner)  |
| 5     | `vy`                  | Kinematic   | Augmented   | Velocity Y (synthetic/SkillCorner)  |
| 6     | `vel_magnitude`       | Kinematic   | Derived     | Speed: sqrt(vxÂ² + vyÂ²)             |
| 7     | `vel_angle`           | Kinematic   | Derived     | Direction of movement (radians)     |
| 8     | `angle_to_goal`       | Contextual  | Engineered  | Angle from player to goal (radians) |
| 9     | `angle_to_ball`       | Contextual  | Engineered  | Angle from player to ball target    |
| 10    | `team_flag`           | Contextual  | Binary      | 1.0=attacking, 0.0=defending        |
| 11    | `in_penalty_box`      | Contextual  | Binary      | 1.0=inside penalty area             |
| 12    | `num_players_5m`      | Density     | Computed    | Count of nearby players (5m radius) |
| 13    | `local_density`       | Density     | Gaussian    | Kernel density score                |

**Feature Quality**:
- âœ… Spatial features: High quality (directly from StatsBomb 360)
- âš ï¸ Velocity features: Synthetic for StatsBomb (temporal augmentation with position perturbations)
- âœ… Velocity features: Real for SkillCorner (10fps tracking)
- âœ… Contextual/Density: Derived features, high quality

---

### 3. Labels and Targets

**Receiver Label** (TacticAI Task 1: Receiver Prediction):
- Type: Multi-class classification (22 classes)
- Format: `receiver_idx` (0-21, node index in graph)
- Coverage: 60.1% of graphs (3,492/5,814 StatsBomb)
- Extracted from: `outcome_player` column (player who touches ball 0-5s after corner)
- Limitation: Player names only (no position data like "striker", "midfielder")

**Shot Label** (TacticAI Task 2: Shot Prediction):
- Type: Binary classification
- Format: `shot_label` (1.0 if dangerous, 0.0 otherwise)
- Definition: `dangerous = (outcome == "Shot") OR (goal_scored == True)`
- Class balance: 18.2% positive (1,056/5,814)
- Rationale: Changed from "goal only" (1.3%) to "shot OR goal" for better balance

**Outcome Categories**:
```
Shot:        1,056 (18.2%) - Includes goals
Loss:        ~2,500 (43%)  - Possession lost
Clearance:   ~1,200 (20%)  - Defensive clearance
Possession:  ~1,000 (17%)  - Attacking team retains
Other:       ~58 (1%)      - Second corner, etc.
```

---

### 4. Data Splits (Prevents Temporal Leakage)

**Splitting Strategy**: By base corner ID (not by graph)
- Ensures all temporal frames from same corner stay in same split
- Stratified by `shot_label` to maintain class balance

**Split Ratios**:
```
Train:       70% (~2,444 graphs with receivers)
Validation:  15% (~524 graphs)
Test:        15% (~524 graphs)
```

**Verification**: Zero overlap confirmed (see `DATA_LEAKAGE_FIX_NOTES.md`)

---

### 5. Temporal Augmentation Details

**StatsBomb Temporal Augmentation** (US Soccer Federation approach):
- 5 temporal frames per base corner: t = -2s, -1s, 0s, +1s, +2s
- Position perturbations: Gaussian noise (Ïƒ = 0.5 yards)
- Mirror augmentation: Horizontal flip for pitch symmetry
- Result: 5,814 graphs from 1,118 base corners (5.2Ã— increase)

**SkillCorner Temporal Extraction**:
- Real tracking data: 10fps (0.1s intervals)
- Temporal windows: Â±2s around corner kick
- Result: 1,555 graphs from 317 base corners (4.9Ã— increase)

**Combined**: 7,369 total graphs (6.6Ã— augmentation from 1,118 base corners)

---

## Baseline Models: Current Implementation

### What's Already in the Code

#### 1. **Random Baseline** âœ… IMPLEMENTED
**File**: `src/models/baselines.py::RandomReceiverBaseline`

**Architecture**:
- No parameters (random softmax)
- `torch.randn()` â†’ softmax over 22 players

**Expected Performance** (sanity check):
- Top-1: 4.5% (1/22)
- Top-3: 13.6% (3/22)
- Top-5: 22.7% (5/22)

**Purpose**: Verify labels aren't random

---

#### 2. **MLP Baseline** âœ… IMPLEMENTED
**File**: `src/models/baselines.py::MLPReceiverBaseline`

**Architecture**:
```
Input:  Flatten all players â†’ [batch, 22 Ã— 14 = 308]
Layer 1: Linear(308 â†’ 256) + ReLU + Dropout(0.3)
Layer 2: Linear(256 â†’ 128) + ReLU + Dropout(0.3)
Layer 3: Linear(128 â†’ 22)
Output: Logits [batch, 22] â†’ softmax
```

**Parameters**: ~50k trainable parameters

**Training Plan** (Day 5-6):
- Optimizer: Adam (lr=1e-3, weight_decay=1e-4)
- Steps: 10,000
- Batch size: 32
- Evaluation: Every 500 steps

**Expected Performance**:
- Top-1: > 20%
- Top-3: > 45%
- **Decision point**: If Top-3 < 40%, STOP and debug data pipeline

**What it tests**: Can neural networks learn receiver patterns without graph structure?

---

### What's MISSING from the Implementation Plan

#### 3. **XGBoost Baseline** âŒ NOT IN PLAN OR CODE

**Why it should be added**:
Your supervisor is right - Random Forest isn't ideal. But **XGBoost is missing entirely** from the TacticAI plan. This is a gap because:

1. **Scientific rigor**: Need a strong classical ML baseline to prove GNNs are necessary
2. **Industry standard**: XGBoost is the default for tabular sports analytics
3. **Interpretability**: Feature importance reveals which spatial patterns matter
4. **Publication requirement**: Reviewers will ask "why not just use XGBoost?"

**Proposed Architecture**:
```python
# Engineered features per graph (not per player):
features = [
    # Player-level features (22 Ã— 15 = 330 dims)
    - Per-player: x, y, dist_to_goal, dist_to_ball, team_flag,
                  in_penalty_box, num_players_5m, local_density,
                  closest_opponent_distance, teammates_within_5m,
                  angle_to_goal, angle_to_ball, distance_to_goal_line,
                  is_near_post, is_far_post

    # Team-level aggregate features (~20 dims)
    - Attacking team: avg_x, avg_y, formation_compactness (x/y std dev),
                      players_in_penalty_box, players_in_6yard_box
    - Defending team: defensive_line_y, compactness, zonal_coverage_score

    # Tactical features (~10 dims)
    - Corner type: near_post_delivery, far_post_delivery, short_corner
    - Crowding: total_players_in_box, attacker_defender_ratio
]

Total: ~360 features flattened per graph
```

**XGBoost Hyperparameters**:
```python
XGBClassifier(
    objective='multi:softmax',  # 22-class classification
    num_class=22,
    max_depth=6,
    n_estimators=500,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    eval_metric='mlogloss'
)
```

**Training**:
- 5-fold cross-validation
- Early stopping (patience=50 rounds)
- GridSearchCV for `max_depth` and `learning_rate`

**Expected Performance**:
- Top-1: 25% Â± 2%
- Top-3: 42% Â± 2%
- Top-5: 60% Â± 3%

**Gap to MLP**: +3-5% improvement (MLP learns better features automatically)

---

## What the Plan Says vs. What We Have

### Day 5-6 in TACTICAI_IMPLEMENTATION_PLAN.md

**Current plan says**:
```markdown
- [x] Implement RandomReceiverBaseline
- [x] Implement MLPReceiverBaseline
- [x] Train MLP for 10k steps
```

**What's missing**:
- âŒ No XGBoost baseline
- âŒ No feature engineering for classical ML
- âŒ No comparison table: "XGBoost vs MLP vs GNN"

**Why this matters**:
The plan jumps from Random â†’ MLP â†’ GNN, missing the critical question: *"Can classical ML with domain expertise compete with deep learning?"*

Expected progression should be:
```
Random (13.6% top-3)
   â†“  +28% absolute gain
XGBoost (42% top-3)  â† Domain expertise + feature engineering
   â†“  +4% absolute gain
MLP (46% top-3)      â† Neural networks learn features automatically
   â†“  +18% absolute gain
GNN (64% top-3)      â† Graph structure + relational reasoning
```

This tells the story: *"Even with expert features, classical ML plateaus. GNNs succeed because they model player interactions."*

---

## Baseline Comparison Matrix

| Baseline      | Implementation | Training Script | Expected Top-3 | Purpose                          |
|---------------|----------------|-----------------|----------------|----------------------------------|
| Random        | âœ… Complete    | âŒ Missing      | 13.6%          | Sanity check (labels not random) |
| **XGBoost**   | âŒ Missing     | âŒ Missing      | **42%**        | **Classical ML ceiling**         |
| MLP           | âœ… Complete    | âŒ Missing      | 46%            | Neural baseline (no graph)       |
| GCN           | âŒ Not started | âŒ Missing      | 52%            | Graph structure (no attention)   |
| GAT           | âŒ Not started | âŒ Missing      | 57%            | Attention (no D2 symmetry)       |
| GATv2 + D2    | âœ… Encoder done| âŒ Missing      | 64%            | **Our main model**               |

**Key insight**: The XGBoost gap is critical for publication. Without it, we can't claim GNNs are *necessary* vs. just *better than a weak MLP*.

---

## Recommended Next Steps

### Option A: Follow Current Plan (Faster)
1. âœ… Skip XGBoost
2. âœ… Train Random + MLP baselines (Day 5-6)
3. âœ… If MLP Top-3 > 45%, proceed to GNN (Day 7 decision point)
4. âœ… Publish with caveat: "No classical ML baseline tested"

**Timeline**: 2 days
**Risk**: Reviewers will ask "why not XGBoost?"

---

### Option B: Add XGBoost (Recommended for Publication)
1. âœ… Implement XGBoost baseline with engineered features (1 day)
2. âœ… Train Random + XGBoost + MLP (1 day)
3. âœ… Proceed to GNN with stronger baseline story (Day 7)
4. âœ… Publication-ready comparison table

**Timeline**: 3 days (+1 day for implementation)
**Benefit**: Stronger scientific contribution

---

## Training Scripts Status

**What exists**:
- âœ… `src/models/baselines.py` (Random + MLP classes)
- âœ… `src/data/receiver_data_loader.py` (Data loading)

**What's missing**:
- âŒ `scripts/training/train_baseline.py` (actual training script)
- âŒ XGBoost implementation
- âŒ Feature engineering for XGBoost
- âŒ Evaluation script with top-k metrics

**Next file to create**: `scripts/training/train_baseline.py`

---

## Dataset Files Inventory

```
data/graphs/adjacency_team/
â”œâ”€â”€ statsbomb_graphs.pkl                              (15 MB)  - Original 1,118 corners
â”œâ”€â”€ statsbomb_temporal_augmented.pkl                  (75 MB)  - 5,814 augmented
â”œâ”€â”€ statsbomb_temporal_augmented_with_receiver.pkl    (75 MB)  - âœ… USE THIS (3,492 with receivers)
â”œâ”€â”€ skillcorner_temporal_graphs.pkl                   (31 MB)  - 1,555 SkillCorner
â”œâ”€â”€ combined_temporal_graphs.pkl                      (105 MB) - All 7,369 combined
â””â”€â”€ combined_temporal_graphs_with_receiver.pkl        (105 MB) - All with receivers (0% coverage - broken)
```

**Correct file to use**: `statsbomb_temporal_augmented_with_receiver.pkl`
- 5,814 graphs total
- 3,492 with valid receiver labels (60.1%)
- 1,056 dangerous situations (18.2%)

---

## Summary Table: What's Ready vs. What's Needed

| Component               | Status      | Location                                    | Notes                          |
|-------------------------|-------------|---------------------------------------------|--------------------------------|
| Dataset                 | âœ… Ready    | `statsbomb_temporal_augmented_with_receiver.pkl` | 3,492 usable graphs        |
| Data Loader             | âœ… Ready    | `src/data/receiver_data_loader.py`         | Masks velocities, splits correctly |
| Random Baseline         | âœ… Ready    | `src/models/baselines.py`                  | Tested, working                |
| MLP Baseline            | âœ… Ready    | `src/models/baselines.py`                  | Tested, working                |
| XGBoost Baseline        | âŒ Missing  | -                                           | **Recommended to add**         |
| Training Script         | âŒ Missing  | `scripts/training/train_baseline.py`       | Next to implement              |
| Evaluation Script       | âŒ Missing  | `scripts/evaluation/evaluate_receiver.py`  | Needed for test set            |
| GATv2 Encoder           | âœ… Ready    | `src/models/gat_encoder.py`                | Tested (9/9 tests passing)     |
| D2 Augmentation         | âœ… Ready    | `src/data/augmentation.py`                 | Tested (17/17 tests passing)   |
| Receiver Predictor Head | âŒ Missing  | `src/models/receiver_predictor.py`         | Next after baselines           |

---

## Conclusion

**Dataset**: âœ… High quality, well-engineered, ready for training
**Baselines**: âš ï¸ MLP implemented, but missing XGBoost (critical gap)
**Next critical task**: Implement `scripts/training/train_baseline.py` to validate data pipeline

**Recommendation**: Add XGBoost baseline before proceeding to GNN training to strengthen scientific contribution.
